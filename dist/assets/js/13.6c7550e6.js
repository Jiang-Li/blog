(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{372:function(t,s,a){"use strict";a.r(s);var n=a(0),e=Object(n.a)({},function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("I often use R, Python, SAS, SQL, and Bash in different\ntasks at the same time.\nTo make the switch between different languages easier, I built a list of the commonly-used script for a quick reference.\nA simulated sample data set with missing values and duplicated values was used.")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("set.seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nN "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" tibble"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\ndimension1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"I"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"II"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"III"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" N"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\ndimension2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"A"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"B"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"C"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" N"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nmeasure1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" N"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nmeasure2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" N"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndf "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" as_tibble"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lapply"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                       "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n                         r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("sample"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("NA")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                  prob "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.85")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.15")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                  size "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" length"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("r"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                                  replace "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("TRUE")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n                       "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nhead"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 6 x 4\n##   dimension1 dimension2 measure1 measure2\n##   <chr>      <chr>         <int>    <int>\n## 1 I          <NA>              7        7\n## 2 III        B                 3        8\n## 3 I          A                 4       10\n## 4 II         <NA>              7        3\n## 5 I          A                 9        1\n## 6 III        A                10       NA\n")])])]),a("h2",{attrs:{id:"row-and-column"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#row-and-column","aria-hidden":"true"}},[t._v("#")]),t._v(" Row and Column")]),t._v(" "),a("h3",{attrs:{id:"r"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# row count")]),t._v("\nnrow"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## [1] 1000\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[t._v("df "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" count"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 1 x 1\n##       n\n##   <int>\n## 1  1000\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# column names")]),t._v("\nnames"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('## [1] "dimension1" "dimension2" "measure1"   "measure2"\n')])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# data types")]),t._v("\nlapply"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" class"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('## $dimension1\n## [1] "character"\n## \n## $dimension2\n## [1] "character"\n## \n## $measure1\n## [1] "integer"\n## \n## $measure2\n## [1] "integer"\n')])])]),a("h3",{attrs:{id:"python"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# row count")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# column names")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("list")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# data types")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dtypes  \n")])])]),a("h3",{attrs:{id:"sas"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sas","aria-hidden":"true"}},[t._v("#")]),t._v(" SAS")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("PROC CONTENTS DATA=df;\nRUN;\n")])])]),a("h3",{attrs:{id:"sql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sql","aria-hidden":"true"}},[t._v("#")]),t._v(" SQL")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* row count */")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("COUNT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" df \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* column names */")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("TOP")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" df \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("/* data types */")]),t._v("  \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("SELECT")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("FROM")]),t._v(" INFORMATION_SCHEMA"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("COLUMNS")]),t._v("  \n")])])]),a("h3",{attrs:{id:"bash"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bash","aria-hidden":"true"}},[t._v("#")]),t._v(" Bash")]),t._v(" "),a("div",{staticClass:"language-bash extra-class"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# row count")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("wc")]),t._v(" -l  filename \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# column names")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("head")]),t._v(" -1 filename \n")])])]),a("h2",{attrs:{id:"missing-values"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#missing-values","aria-hidden":"true"}},[t._v("#")]),t._v(" Missing Values")]),t._v(" "),a("h3",{attrs:{id:"r-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r-2","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# count missing by columns")]),t._v("\ncolSums"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("is.na"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## dimension1 dimension2   measure1   measure2 \n##        163        163        143        156\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# drop rows with missing")]),t._v("\nna.omit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 518 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <int>    <int>\n##  1 III        B                 3        8\n##  2 I          A                 4       10\n##  3 I          A                 9        1\n##  4 III        A                 8        8\n##  5 II         C                 2        9\n##  6 III        C                 7        1\n##  7 I          A                 9        6\n##  8 I          A                 2        4\n##  9 II         A                 1        9\n## 10 I          B                 9        2\n## # … with 508 more rows\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# drop rows with all missing")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("rowSums"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("is.na"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 1,000 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <int>    <int>\n##  1 I          <NA>              7        7\n##  2 III        B                 3        8\n##  3 I          A                 4       10\n##  4 II         <NA>              7        3\n##  5 I          A                 9        1\n##  6 III        A                10       NA\n##  7 III        A                 8        8\n##  8 <NA>       C                 2        7\n##  9 II         C                 2        9\n## 10 III        C                 7        1\n## # … with 990 more rows\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# drop columns with all missing")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("colSums"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!")]),t._v("is.na"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 1,000 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <int>    <int>\n##  1 I          <NA>              7        7\n##  2 III        B                 3        8\n##  3 I          A                 4       10\n##  4 II         <NA>              7        3\n##  5 I          A                 9        1\n##  6 III        A                10       NA\n##  7 III        A                 8        8\n##  8 <NA>       C                 2        7\n##  9 II         C                 2        9\n## 10 III        C                 7        1\n## # … with 990 more rows\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# fill all missing by 0")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" replace"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" is.na"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("."),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 1,000 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <dbl>    <dbl>\n##  1 I          0                 7        7\n##  2 III        B                 3        8\n##  3 I          A                 4       10\n##  4 II         0                 7        3\n##  5 I          A                 9        1\n##  6 III        A                10        0\n##  7 III        A                 8        8\n##  8 0          C                 2        7\n##  9 II         C                 2        9\n## 10 III        C                 7        1\n## # … with 990 more rows\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# fill missing by columns")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" replace_na"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Unknown"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" measure1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 1,000 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <dbl>    <int>\n##  1 I          <NA>              7        7\n##  2 III        B                 3        8\n##  3 I          A                 4       10\n##  4 II         <NA>              7        3\n##  5 I          A                 9        1\n##  6 III        A                10       NA\n##  7 III        A                 8        8\n##  8 Unknown    C                 2        7\n##  9 II         C                 2        9\n## 10 III        C                 7        1\n## # … with 990 more rows\n")])])]),a("h3",{attrs:{id:"python-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-2","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# count missing by columns")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("isnull"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# drop any missing")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# drop rows with all missing")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("how"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"all"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# drop columns with all missing")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dropna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("axis"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" how"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'all'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# fill all missing by 0")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fillna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# fill missing by columns")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fillna"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("value "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimension1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Unknown"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"unique"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#unique","aria-hidden":"true"}},[t._v("#")]),t._v(" Unique")]),t._v(" "),a("h3",{attrs:{id:"r-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r-3","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# unique row")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" distinct"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 766 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <int>    <int>\n##  1 I          <NA>              7        7\n##  2 III        B                 3        8\n##  3 I          A                 4       10\n##  4 II         <NA>              7        3\n##  5 I          A                 9        1\n##  6 III        A                10       NA\n##  7 III        A                 8        8\n##  8 <NA>       C                 2        7\n##  9 II         C                 2        9\n## 10 III        C                 7        1\n## # … with 756 more rows\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# unique row by columns")]),t._v("\ndf "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" distinct"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" .keep_all "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 16 x 4\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <int>    <int>\n##  1 I          <NA>              7        7\n##  2 III        B                 3        8\n##  3 I          A                 4       10\n##  4 II         <NA>              7        3\n##  5 III        A                10       NA\n##  6 <NA>       C                 2        7\n##  7 II         C                 2        9\n##  8 III        C                 7        1\n##  9 III        <NA>              5        4\n## 10 I          C                NA       10\n## 11 II         A                 1        9\n## 12 II         B                NA        2\n## 13 <NA>       A                 8       10\n## 14 I          B                 9        2\n## 15 <NA>       B                 9        4\n## 16 <NA>       <NA>              6       NA\n")])])]),a("h3",{attrs:{id:"python-3"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-3","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# unique row")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("drop_duplicates"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# unique row by columns")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("drop_duplicates"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("subset"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"level-count"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#level-count","aria-hidden":"true"}},[t._v("#")]),t._v(" Level Count")]),t._v(" "),a("h3",{attrs:{id:"r-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r-4","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# distribution")]),t._v("\ntable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## \n##   I  II III \n## 295 275 267\n")])])]),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# contingency table")]),t._v("\ntable"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("$")]),t._v("dimension2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("##      \n##        A  B  C\n##   I   89 80 79\n##   II  71 89 70\n##   III 75 66 86\n")])])]),a("h3",{attrs:{id:"python-4"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-4","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# distribution")]),t._v("\ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value_counts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# contingency table")]),t._v("\npd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("crosstab"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("dimension2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"summary"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#summary","aria-hidden":"true"}},[t._v("#")]),t._v(" Summary")]),t._v(" "),a("h3",{attrs:{id:"r-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r-5","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# summarize the total, percent, ratio, and ratio")]),t._v("\n\ndf "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n  group_by"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n  summarise"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    measure1 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    measure2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    count "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n  mutate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    measure1_percent "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" measure1"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    ratio "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" measure1"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("measure2\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n  mutate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    ratio_relativity "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ratio"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 4 x 7\n##   dimension1 measure1 measure2 count measure1_percent ratio\n##   <chr>         <int>    <int> <int>            <dbl> <dbl>\n## 1 <NA>            749      752   163            0.157 0.996\n## 2 I              1480     1460   295            0.311 1.01 \n## 3 II             1288     1261   275            0.271 1.02 \n## 4 III            1244     1320   267            0.261 0.942\n## # … with 1 more variable: ratio_relativity <dbl>\n")])])]),a("h3",{attrs:{id:"python-5"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-5","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# summarize the total, percent, ratio, and relativity")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("oneway")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Series"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"count"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure1_percent"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ratio"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ratio_relativity"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("g"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v(" \n        "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  \ndf"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupby"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimension1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("apply")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oneway"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"merge"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#merge","aria-hidden":"true"}},[t._v("#")]),t._v(" Merge")]),t._v(" "),a("h3",{attrs:{id:"r-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r-6","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# join tables with different key names")]),t._v("\ndf2 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" df "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n  group_by"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n  summarise"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    measure3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    measure4 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("measure2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n  rename"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension3 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension4 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dimension2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nleft_join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  by "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimension1"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimension3"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimension2"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimension4"')]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 1,000 x 6\n##    dimension1 dimension2 measure1 measure2 measure3 measure4\n##    <chr>      <chr>         <int>    <int>    <int>    <int>\n##  1 I          <NA>              7        7      229      195\n##  2 III        B                 3        8      314      337\n##  3 I          A                 4       10      461      480\n##  4 II         <NA>              7        3      226      180\n##  5 I          A                 9        1      461      480\n##  6 III        A                10       NA      353      356\n##  7 III        A                 8        8      353      356\n##  8 <NA>       C                 2        7      206      226\n##  9 II         C                 2        9      340      333\n## 10 III        C                 7        1      386      442\n## # … with 990 more rows\n")])])]),a("h3",{attrs:{id:"python-6"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-6","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# join tables with different key names")]),t._v("\npd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("merge"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" df2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  how"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"left"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n  left_on"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimesnion1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimesnion2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  right_on"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimesnion3"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"dimesnion4"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h2",{attrs:{id:"reshape"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reshape","aria-hidden":"true"}},[t._v("#")]),t._v(" Reshape")]),t._v(" "),a("h3",{attrs:{id:"r-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#r-7","aria-hidden":"true"}},[t._v("#")]),t._v(" R")]),t._v(" "),a("div",{staticClass:"language-r extra-class"},[a("pre",{pre:!0,attrs:{class:"language-r"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# wide to long")]),t._v("\ndf_reshape "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<-")]),t._v(" df "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" gather"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("c"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure1"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure2"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                            key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"measure"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"values"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# long to wide: the value must be unqiue by other variales")]),t._v("\ndf_reshape "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n  group_by"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dimension1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dimension2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" measure"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v("\n  summarise"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sum"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" na.rm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" T"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token percent-operator operator"}},[t._v("%>%")]),t._v(" \n  spread"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" measure"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" value "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" values"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("## # A tibble: 16 x 4\n## # Groups:   dimension1, dimension2 [16]\n##    dimension1 dimension2 measure1 measure2\n##    <chr>      <chr>         <int>    <int>\n##  1 I          A               461      480\n##  2 I          B               392      426\n##  3 I          C               398      359\n##  4 I          <NA>            229      195\n##  5 II         A               282      358\n##  6 II         B               440      390\n##  7 II         C               340      333\n##  8 II         <NA>            226      180\n##  9 III        A               353      356\n## 10 III        B               314      337\n## 11 III        C               386      442\n## 12 III        <NA>            191      185\n## 13 <NA>       A               178      206\n## 14 <NA>       B               209      206\n## 15 <NA>       C               206      226\n## 16 <NA>       <NA>            156      114\n")])])]),a("h3",{attrs:{id:"python-7"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-7","aria-hidden":"true"}},[t._v("#")]),t._v(" Python")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("df_reshape "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pd"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("melt"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                     id_vars"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                     value_vars"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'measure1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'measure2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("df_reshape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupby"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'variable'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    as_index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("False")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n           "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pivot_table"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("index"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'dimension2'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                        columns"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'variable'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" values"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'value'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])])},[],!1,null,null,null);s.default=e.exports}}]);